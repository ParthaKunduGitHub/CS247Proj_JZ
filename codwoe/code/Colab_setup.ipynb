{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthaKunduGitHub/CS247Proj_JZ/blob/main/codwoe/code/Colab_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive or clone repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCSU4HrvkVDq",
        "outputId": "a487aa30-d4fa-4946-f024-927a100b0bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "from google.colab import userdata\n",
        "gh_pat = userdata.get('gh_pat')\n",
        "gh_username = userdata.get('gh_username')\n",
        "!rm -rf CS247Proj_JZ\n",
        "!git clone https://{gh_username}:{gh_pat}@github.com/ParthaKunduGitHub/CS247Proj_JZ.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGy1_W7kcg7U",
        "outputId": "e0377746-85d9-4e09-f255-f186f2454144"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS247Proj_JZ'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 137 (delta 49), reused 111 (delta 33), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (137/137), 1.84 MiB | 4.53 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current Directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "RdwYSJibltw4",
        "outputId": "dc0add3d-cc30-4f61-cf83-494ace46ea66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd CS247Proj_JZ"
      ],
      "metadata": {
        "id": "T98XkYHalx-_",
        "outputId": "f1148ec6-520d-4bef-ee6e-d138039f5d18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CS247Proj_JZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Current Directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "kSNraHVJl3wC",
        "outputId": "c8ea53a5-7756-4411-ac17-3d8320d49b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/CS247Proj_JZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z9FuihZQUWhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gfQ17SmkfOK",
        "outputId": "65cefc8a-6391-4cf7-ab76-2643bfac6f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/com_sci_247/codwoe\n"
          ]
        }
      ],
      "source": [
        "# cd /content/drive/MyDrive/com_sci_247/codwoe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Rustup\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential cmake libhdf5-dev swig wget\n",
        "!curl https://sh.rustup.rs -sSf | sh -s -- -y\n",
        "!export PATH=\"$HOME/.cargo/bin:$PATH\""
      ],
      "metadata": {
        "id": "Dawk1VUebnNX",
        "outputId": "29931b22-9052-47cd-939d-7b688a9007be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libhdf5-dev is already the newest version (1.10.7+repack-4ubuntu2).\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mIt looks like you have an existing rustup settings file at:\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0m/root/.rustup/settings.toml\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mRustup will install the default toolchain as specified in the settings file,\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0minstead of the one inferred from the default host triple.\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mprofile set to 'default'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mUpdating existing toolchain, profile choice will be ignored\n",
            "\u001b[0m\u001b[1minfo: \u001b[0msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[0m\u001b[1mstable-x86_64-unknown-linux-gnu unchanged\u001b[0m - rustc 1.85.0 (4d91de4e4 2025-02-17)\n",
            "\n",
            "\u001b[0m\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[0m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[0m\u001b[1mPATH\u001b[0m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, you need to source\n",
            "the corresponding \u001b[0m\u001b[1menv\u001b[0m file under $HOME/.cargo.\n",
            "\n",
            "This is usually done by running one of the following (note the leading DOT):\n",
            ". \"$HOME/.cargo/env\"            # For sh/bash/zsh/ash/dash/pdksh\n",
            "source \"$HOME/.cargo/env.fish\"  # For fish\n",
            "source \"$HOME/.cargo/env.nu\"    # For nushell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel\n"
      ],
      "metadata": {
        "id": "0IuIWG4CcHzJ",
        "outputId": "10a3fa01-f97b-4e57-c46f-2e1e596401a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.8.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HFFKvhs4tAp5",
        "outputId": "c36eb9ea-8c82-460b-d5ca-6bc502928b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: cachetools>=4.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2025.1.31)\n",
            "Requirement already satisfied: chardet>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (5.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (8.1.8)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: filelock>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.17.0)\n",
            "Requirement already satisfied: google-auth>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.2.1)\n",
            "Requirement already satisfied: grpcio>=1.51.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.70.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: idna>=3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.4.8)\n",
            "Requirement already satisfied: Markdown>=3.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (3.7)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.10.0)\n",
            "Collecting moverscore>=1.0.3 (from -r requirements.txt (line 17))\n",
            "  Downloading moverscore-1.0.3.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.26.4)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (3.2.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (24.2)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (11.1.0)\n",
            "Collecting portalocker>=2.3.0 (from -r requirements.txt (line 23))\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: protobuf<6.0.0,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (4.25.6)\n",
            "Requirement already satisfied: pyasn1>=0.4.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (0.4.1)\n",
            "Collecting pyemd (from -r requirements.txt (line 27))\n",
            "  Downloading pyemd-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (6.0.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (2.0.0)\n",
            "Requirement already satisfied: rsa>=4.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (4.9)\n",
            "Collecting sacremoses>=0.0.53 (from -r requirements.txt (line 35))\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (0.2.0)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (2.18.0)\n",
            "Requirement already satisfied: tensorboard-data-server>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (0.7.2)\n",
            "Collecting tensorboard-plugin-wit>=1.8.0 (from -r requirements.txt (line 40))\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (0.21.0)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (4.48.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 46)) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (3.1.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->-r requirements.txt (line 11)) (2024.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->-r requirements.txt (line 16)) (4.56.0)\n",
            "Collecting typing (from moverscore>=1.0.3->-r requirements.txt (line 17))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->-r requirements.txt (line 32)) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.18.0->-r requirements.txt (line 38)) (75.8.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->-r requirements.txt (line 42))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->-r requirements.txt (line 42)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->-r requirements.txt (line 42)) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.41.0->-r requirements.txt (line 45)) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug>=2.2.3->-r requirements.txt (line 48)) (3.0.2)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading pyemd-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (666 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m666.6/666.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m165.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m201.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m152.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m143.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m149.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: moverscore, typing\n",
            "  Building wheel for moverscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moverscore: filename=moverscore-1.0.3-py3-none-any.whl size=8011 sha256=09599d037e641bacad0f8dc5a4fe234de161abc43e6345d62e9d7d49842070b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/56/44/23b9c85158529e8177d069f01d064e0ff2252c0d5b21608548\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26365 sha256=db2b83c57111fd9b46ff1bd5017844b2bccf0578a23ed8ba133cb6110f0219f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "Successfully built moverscore typing\n",
            "Installing collected packages: tensorboard-plugin-wit, typing, sacremoses, pyemd, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, moverscore, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed moverscore-1.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.1.1 pyemd-1.0.0 sacremoses-0.1.1 tensorboard-plugin-wit-1.8.1 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "b6879fa94b104399897f558611386de7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize==0.9.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyZTJENwrzwc",
        "outputId": "c5b9ceb7-a2ca-4e65-cfbf-fbeb696f02e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize==0.9.0 in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize==0.9.0) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize==0.9.0) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize==0.9.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize==0.9.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize==0.9.0) (1.6.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.0) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->scikit-optimize==0.9.0) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Train and Evaluate Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDPPdIwPajT5"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "66XqkuamajT5",
        "outputId": "72a9648a-7db4-4c3d-a404-2ef39e66b8ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/drive/MyDrive/com_sci_247/codwoe\n",
            "python3: can't open file '/content/drive/MyDrive/com_sci_247/codwoe/./codwoe/code/code/revdict.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "\n",
        "\n",
        "\n",
        "!python3 ./codwoe/code/code/revdict.py --do_train \\\n",
        "    --train_file data/en.train.json \\\n",
        "    --dev_file data/en.dev.json \\\n",
        "    --device cuda \\\n",
        "    --target_arch sgns \\\n",
        "    --summary_logdir baseline_archs/logs/revdict-baseline \\\n",
        "    --save_dir baseline_archs/models/revdict-baseline \\\n",
        "    --spm_model_path baseline_archs/models/revdict-baseline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC-8z2UxajT6"
      },
      "source": [
        "#### Testing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNynTEdrajT6",
        "outputId": "05afa799-b2c8-40fb-a000-36c3fb088825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-04 23:32:39.048254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741131159.068632   14339 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741131159.075363   14339 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-04 23:32:39.097018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-04 23:32:41,964 [DEBUG] revdict.py: Performing revdict prediction\n",
            "/content/drive/MyDrive/codwoe/baseline_archs/code/models.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file)\n",
            "/content/drive/MyDrive/codwoe/baseline_archs/code/data.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(file)\n",
            "Pred.: 100% 6208/6208 [00:00<00:00, 7988.61it/s]\n"
          ]
        }
      ],
      "source": [
        "!python3 baseline_archs/code/revdict.py --do_pred \\\n",
        "    --test_file data/en.test.revdict.json \\\n",
        "    --device cuda \\\n",
        "    --target_arch sgns \\\n",
        "    --save_dir baseline_archs/models/revdict-baseline/sgns \\\n",
        "    --pred_file baseline_archs/models/revdict-baseline/sgns/revdict_predictions_sgns.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n84M6KLmkp2i",
        "outputId": "acd00a15-c919-4057-a3e5-8d2598f37755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-04 23:34:27.556998: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1741131267.577504   14927 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1741131267.583653   14927 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-04 23:34:27.604048: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_attentions\": true,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
            "2025-03-04 23:34:38,504 [DEBUG] check_output.py: File \"baseline_archs/models/revdict-baseline/sgns/revdict_predictions_sgns.json\": no problems were identified.\n",
            "The submission will be understood as follows:\n",
            "\tSubmission on track revdict for language en, 6208 predictions.\n",
            "\tSubmission predicts these embeddings: sgns.\n"
          ]
        }
      ],
      "source": [
        "!python3 code/score.py \\\n",
        "    baseline_archs/models/revdict-baseline/sgns/revdict_predictions_sgns.json \\\n",
        "    --reference_files_dir data \\\n",
        "    --output_file baseline_archs/models/revdict-baseline/sgns/scores.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2yunZ6Rofv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}